{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Assumptions Analysis\n",
    "\n",
    "**Date:** 28 September 2024\n",
    "\n",
    "**Topic:** Validation of linear regression assumptions\n",
    "\n",
    "This notebook covers:\n",
    "1. Linearity Assessment\n",
    "2. Homoscedasticity Testing\n",
    "3. Normality of Residuals\n",
    "4. Independence of Errors\n",
    "5. Real-world Dataset Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Synthetic Dataset Analysis\n",
    "\n",
    "### 2.1 Dataset Generation and Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset with controlled properties\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Feature dimensions: {X_train.shape[1]} feature(s)\")\n",
    "\n",
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Training R²: {model.score(X_train, y_train):.4f}\")\n",
    "print(f\"Testing R²: {model.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linearity Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression plot to assess linearity\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Actual vs Predicted\n",
    "ax1.scatter(X_test.flatten(), y_test, label=\"Actual\", alpha=0.6, color=\"blue\")\n",
    "ax1.scatter(X_test.flatten(), y_pred, label=\"Predicted\", alpha=0.6, color=\"red\")\n",
    "ax1.set_xlabel('Feature Value')\n",
    "ax1.set_ylabel('Target Value')\n",
    "ax1.set_title('Actual vs Predicted Values')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Perfect prediction line\n",
    "ax2.scatter(y_test, y_pred, alpha=0.6)\n",
    "min_val = min(y_test.min(), y_pred.min())\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "ax2.set_xlabel('Actual Values')\n",
    "ax2.set_ylabel('Predicted Values')\n",
    "ax2.set_title('Predicted vs Actual (Linearity Check)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Basic residual plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test.flatten(), residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2, label='Zero Line')\n",
    "plt.xlabel('Feature Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Feature Values')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add horizontal lines for pattern detection\n",
    "std_resid = np.std(residuals)\n",
    "plt.axhline(y=2*std_resid, color='orange', linestyle=':', alpha=0.7, label='+2σ')\n",
    "plt.axhline(y=-2*std_resid, color='orange', linestyle=':', alpha=0.7, label='-2σ')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Residual Statistics:\")\n",
    "print(f\"Mean: {np.mean(residuals):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(residuals):.4f}\")\n",
    "print(f\"Min: {np.min(residuals):.4f}\")\n",
    "print(f\"Max: {np.max(residuals):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homoscedasticity Testing\n",
    "\n",
    "### 3.1 Residuals vs Fitted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test homoscedasticity assumption\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Residuals vs Predicted Values\n",
    "ax1.scatter(y_pred, residuals, alpha=0.6)\n",
    "ax1.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Predicted Values')\n",
    "ax1.set_ylabel('Residuals')\n",
    "ax1.set_title('Residuals vs Predicted Values')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Absolute Residuals vs Predicted Values\n",
    "ax2.scatter(y_pred, np.abs(residuals), alpha=0.6, color='orange')\n",
    "ax2.set_xlabel('Predicted Values')\n",
    "ax2.set_ylabel('Absolute Residuals')\n",
    "ax2.set_title('Scale-Location Plot (Homoscedasticity Check)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line to scale-location plot\n",
    "z = np.polyfit(y_pred, np.abs(residuals), 1)\n",
    "p = np.poly1d(z)\n",
    "ax2.plot(sorted(y_pred), p(sorted(y_pred)), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Heteroscedasticity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset with heteroscedasticity\n",
    "np.random.seed(42)\n",
    "X_hetero = np.random.rand(200, 1) * 100\n",
    "# Variance increases with X\n",
    "y_hetero = 2 * X_hetero.squeeze() + np.random.normal(0, X_hetero.squeeze() * 0.5, 200)\n",
    "\n",
    "# Split and fit model\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
    "    X_hetero, y_hetero, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "model_hetero = LinearRegression()\n",
    "model_hetero.fit(X_train_h, y_train_h)\n",
    "y_pred_h = model_hetero.predict(X_test_h)\n",
    "residuals_h = y_test_h - y_pred_h\n",
    "\n",
    "# Visualize heteroscedasticity\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Residuals plot\n",
    "ax1.scatter(y_pred_h, residuals_h, alpha=0.6)\n",
    "ax1.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Predicted Values')\n",
    "ax1.set_ylabel('Residuals')\n",
    "ax1.set_title('Heteroscedastic Example: Residuals vs Predicted')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Absolute residuals (Scale-Location)\n",
    "ax2.scatter(y_pred_h, np.abs(residuals_h), alpha=0.6, color='orange')\n",
    "ax2.set_xlabel('Predicted Values')\n",
    "ax2.set_ylabel('Absolute Residuals')\n",
    "ax2.set_title('Scale-Location Plot (Shows Heteroscedasticity)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Heteroscedasticity Pattern:\")\n",
    "print(\"Notice how the spread of residuals increases with predicted values.\")\n",
    "print(\"This violates the homoscedasticity assumption.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normality of Residuals\n",
    "\n",
    "### 4.1 Histogram and Kernel Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normality assumption with multiple visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Histogram with normal curve overlay\n",
    "ax1.hist(residuals, bins=20, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "mu, sigma = np.mean(residuals), np.std(residuals)\n",
    "x = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "ax1.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal Distribution')\n",
    "ax1.set_xlabel('Residuals')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Histogram of Residuals with Normal Overlay')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "ax2.boxplot(residuals, vert=True)\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Box Plot of Residuals')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot (Quantile-Quantile)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Kernel density estimate\n",
    "sns.histplot(residuals, kde=True, ax=ax4, stat='density', alpha=0.7)\n",
    "ax4.set_xlabel('Residuals')\n",
    "ax4.set_ylabel('Density')\n",
    "ax4.set_title('Histogram with Kernel Density Estimate')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Statistical Normality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform statistical tests for normality\n",
    "from scipy.stats import shapiro, normaltest, kstest\n",
    "\n",
    "print(\"NORMALITY TESTS FOR RESIDUALS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Shapiro-Wilk test\n",
    "shapiro_stat, shapiro_p = shapiro(residuals)\n",
    "print(f\"\\n1. Shapiro-Wilk Test:\")\n",
    "print(f\"   Statistic: {shapiro_stat:.4f}\")\n",
    "print(f\"   p-value: {shapiro_p:.4f}\")\n",
    "print(f\"   Result: {'Normal' if shapiro_p > 0.05 else 'Not Normal'} (α = 0.05)\")\n",
    "\n",
    "# D'Agostino's normality test\n",
    "dagostino_stat, dagostino_p = normaltest(residuals)\n",
    "print(f\"\\n2. D'Agostino's Normality Test:\")\n",
    "print(f\"   Statistic: {dagostino_stat:.4f}\")\n",
    "print(f\"   p-value: {dagostino_p:.4f}\")\n",
    "print(f\"   Result: {'Normal' if dagostino_p > 0.05 else 'Not Normal'} (α = 0.05)\")\n",
    "\n",
    "# Kolmogorov-Smirnov test\n",
    "ks_stat, ks_p = kstest(residuals, 'norm', args=(np.mean(residuals), np.std(residuals)))\n",
    "print(f\"\\n3. Kolmogorov-Smirnov Test:\")\n",
    "print(f\"   Statistic: {ks_stat:.4f}\")\n",
    "print(f\"   p-value: {ks_p:.4f}\")\n",
    "print(f\"   Result: {'Normal' if ks_p > 0.05 else 'Not Normal'} (α = 0.05)\")\n",
    "\n",
    "# Summary\n",
    "tests_passed = sum([shapiro_p > 0.05, dagostino_p > 0.05, ks_p > 0.05])\n",
    "print(f\"\\nSUMMARY: {tests_passed}/3 tests support normality assumption.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-World Dataset: Wine Quality\n",
    "\n",
    "### 5.1 Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine quality dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "wine_data = pd.read_csv(url, delimiter=\";\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"Wine Quality Dataset Information:\")\n",
    "print(f\"Shape: {wine_data.shape}\")\n",
    "print(f\"\\nColumns: {list(wine_data.columns)}\")\n",
    "print(f\"\\nTarget variable: alcohol\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(wine_data.head())\n",
    "\n",
    "# Prepare features and target\n",
    "X_wine = wine_data.drop(\"alcohol\", axis=1)\n",
    "y_wine = wine_data[\"alcohol\"]\n",
    "\n",
    "# Split the data\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"Training: {X_train_wine.shape[0]} samples\")\n",
    "print(f\"Testing: {X_test_wine.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model Fitting and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model on wine data\n",
    "model_wine = LinearRegression()\n",
    "model_wine.fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_wine = model_wine.predict(X_test_wine)\n",
    "residuals_wine = y_test_wine - y_pred_wine\n",
    "\n",
    "# Calculate performance metrics\n",
    "train_r2 = model_wine.score(X_train_wine, y_train_wine)\n",
    "test_r2 = model_wine.score(X_test_wine, y_test_wine)\n",
    "mse = np.mean(residuals_wine**2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Wine Quality Regression Results:\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"Training R²: {train_r2:.4f}\")\n",
    "print(f\"Testing R²: {test_r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Mean Alcohol Content: {y_wine.mean():.2f}\")\n",
    "print(f\"Std Alcohol Content: {y_wine.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Comprehensive Residual Analysis for Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive residual analysis plots\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Residuals vs Predicted\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "plt.scatter(y_pred_wine, residuals_wine, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Predicted Values')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Predicted vs Actual\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "plt.scatter(y_test_wine, y_pred_wine, alpha=0.6)\n",
    "min_val = min(y_test_wine.min(), y_pred_wine.min())\n",
    "max_val = max(y_test_wine.max(), y_pred_wine.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "plt.xlabel('Actual Alcohol Content')\n",
    "plt.ylabel('Predicted Alcohol Content')\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Scale-Location plot\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "plt.scatter(y_pred_wine, np.abs(residuals_wine), alpha=0.6, color='orange')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Absolute Residuals')\n",
    "plt.title('Scale-Location Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "plt.hist(residuals_wine, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "mu, sigma = np.mean(residuals_wine), np.std(residuals_wine)\n",
    "x = np.linspace(residuals_wine.min(), residuals_wine.max(), 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "stats.probplot(residuals_wine, dist=\"norm\", plot=ax5)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot of residuals\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "plt.boxplot(residuals_wine, vert=True)\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Box Plot of Residuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Wine Dataset Assumption Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical tests for wine dataset residuals\n",
    "print(\"REGRESSION ASSUMPTIONS TESTING - WINE DATASET\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Normality tests\n",
    "shapiro_stat_wine, shapiro_p_wine = shapiro(residuals_wine)\n",
    "print(f\"\\n1. NORMALITY OF RESIDUALS:\")\n",
    "print(f\"   Shapiro-Wilk p-value: {shapiro_p_wine:.6f}\")\n",
    "print(f\"   Conclusion: {'Normal' if shapiro_p_wine > 0.05 else 'Not Normal'} (α = 0.05)\")\n",
    "\n",
    "# Breusch-Pagan test for homoscedasticity (using statsmodels)\n",
    "X_wine_sm = sm.add_constant(X_test_wine)\n",
    "model_sm = sm.OLS(y_test_wine, X_wine_sm).fit()\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "bp_stat, bp_p, bp_f_stat, bp_f_p = het_breuschpagan(model_sm.resid, X_wine_sm)\n",
    "print(f\"\\n2. HOMOSCEDASTICITY:\")\n",
    "print(f\"   Breusch-Pagan p-value: {bp_p:.6f}\")\n",
    "print(f\"   Conclusion: {'Homoscedastic' if bp_p > 0.05 else 'Heteroscedastic'} (α = 0.05)\")\n",
    "\n",
    "# Durbin-Watson test for independence\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "dw_stat = durbin_watson(model_sm.resid)\n",
    "print(f\"\\n3. INDEPENDENCE OF ERRORS:\")\n",
    "print(f\"   Durbin-Watson statistic: {dw_stat:.4f}\")\n",
    "print(f\"   Conclusion: {'Independent' if 1.5 < dw_stat < 2.5 else 'Potential autocorrelation'}\")\n",
    "\n",
    "# Overall assessment\n",
    "assumptions_met = [\n",
    "    shapiro_p_wine > 0.05,  # Normality\n",
    "    bp_p > 0.05,           # Homoscedasticity\n",
    "    1.5 < dw_stat < 2.5    # Independence\n",
    "]\n",
    "\n",
    "print(f\"\\n4. OVERALL ASSESSMENT:\")\n",
    "print(f\"   Assumptions met: {sum(assumptions_met)}/3\")\n",
    "if sum(assumptions_met) == 3:\n",
    "    print(f\"   Status: All major assumptions satisfied\")\n",
    "elif sum(assumptions_met) >= 2:\n",
    "    print(f\"   Status: Most assumptions satisfied - model is reasonably valid\")\n",
    "else:\n",
    "    print(f\"   Status: Multiple assumptions violated - consider model improvements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Recommendations\n",
    "\n",
    "### 6.1 Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"REGRESSION ASSUMPTIONS ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nDATASETS ANALYZED:\")\n",
    "print(f\"1. Synthetic Dataset:\")\n",
    "print(f\"   - Samples: {len(y_test)}\")\n",
    "print(f\"   - R²: {model.score(X_test, y_test):.4f}\")\n",
    "print(f\"   - RMSE: {np.sqrt(np.mean(residuals**2)):.4f}\")\n",
    "\n",
    "print(f\"\\n2. Wine Quality Dataset:\")\n",
    "print(f\"   - Samples: {len(y_test_wine)}\")\n",
    "print(f\"   - Features: {X_wine.shape[1]}\")\n",
    "print(f\"   - R²: {test_r2:.4f}\")\n",
    "print(f\"   - RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\nASSUMPTION CHECKLIST:\")\n",
    "print(\"1. Linearity: Verified through scatter plots and residual analysis\")\n",
    "print(\"2. Independence: Assessed using Durbin-Watson test\")\n",
    "print(\"3. Homoscedasticity: Evaluated with scale-location plots and Breusch-Pagan test\")\n",
    "print(\"4. Normality: Tested using Q-Q plots, histograms, and Shapiro-Wilk test\")\n",
    "\n",
    "print(\"\\nRECOMMENDAT1ONS:\")\n",
    "print(\"- Always perform residual analysis before trusting regression results\")\n",
    "print(\"- Use multiple diagnostic plots for comprehensive assessment\")\n",
    "print(\"- Consider transformations if assumptions are violated\")\n",
    "print(\"- Statistical tests complement visual diagnostics\")\n",
    "print(\"- Real-world data often requires more sophisticated modeling approaches\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}